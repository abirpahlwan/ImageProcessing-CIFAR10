{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## k-Fold Cross Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import necessary packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utility functions for loading CIFAR10 Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Source: https://github.com/snatch59/load-cifar-10/blob/master/load_cifar_10_alt.py\n",
    "\n",
    "def load_batch(file_path):\n",
    "    \"\"\"Load a batch of CIFAR data\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        d = pickle.load(f, encoding='bytes')\n",
    "        # decode utf8\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode('utf8')] = v\n",
    "        d = d_decoded\n",
    "    data = d['data']\n",
    "    labels = d['labels']\n",
    "\n",
    "    data = data.reshape(data.shape[0], 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load CIFAR10 dataset\"\"\"\n",
    "    num_train_samples = 50000\n",
    "\n",
    "    x_train_local = np.empty((num_train_samples, 32, 32, 3), dtype='uint8')\n",
    "    y_train_local = np.empty((num_train_samples,), dtype='uint8')\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        batch_file_path = os.path.join(path, 'data_batch_' + str(i))\n",
    "        (x_train_local[(i - 1) * 10000: i * 10000, :, :, :],\n",
    "         y_train_local[(i - 1) * 10000: i * 10000]) = load_batch(batch_file_path)\n",
    "        \n",
    "    fpath = os.path.join(path, 'test_batch')\n",
    "    x_test_local, y_test_local = load_batch(fpath)\n",
    "\n",
    "    y_train_local = np.reshape(y_train_local, (len(y_train_local), 1))\n",
    "    y_test_local = np.reshape(y_test_local, (len(y_test_local), 1))\n",
    "    \n",
    "    # x_train_local = x_train_local.transpose(0, 2, 3, 1)\n",
    "    # x_test_local = x_test_local.transpose(0, 2, 3, 1)\n",
    "\n",
    "    return (x_train_local, y_train_local), (x_test_local, y_test_local)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert images from RGB to Grayscale & Perform distance measurement"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    \"\"\"Utility function for converting RGB numpy array to Grayscale\"\"\"\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def euclidean_distance(image1, image2):\n",
    "    \"\"\"Compute Euclidean distance between two images\"\"\"\n",
    "    gray1 = rgb2gray(image1)\n",
    "    gray2 = rgb2gray(image2)\n",
    "    \n",
    "    distance = gray1 - gray2\n",
    "    distance_squared = distance ** 2\n",
    "    \n",
    "    return np.sqrt(np.sum(distance_squared))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def manhattan_distance(image1, image2):\n",
    "    \"\"\"Compute Manhattan distance between two images\"\"\"\n",
    "    gray1 = rgb2gray(image1)\n",
    "    gray2 = rgb2gray(image2)\n",
    "    \n",
    "    return np.sum(np.abs(gray1 - gray2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load a batch and test the shapes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data (x_data):  (10000, 32, 32, 3)\n",
      "Train labels (y_data):  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "path = [\"\" for _ in range(10)]\n",
    "path[0] = 'cifar-10-batches-py/data_batch_1'\n",
    "path[1] = 'cifar-10-batches-py/data_batch_2'\n",
    "path[2] = 'cifar-10-batches-py/data_batch_3'\n",
    "path[3] = 'cifar-10-batches-py/data_batch_4'\n",
    "path[4] = 'cifar-10-batches-py/data_batch_5'\n",
    "test_path = 'cifar-10-batches-py/test_batch'\n",
    "\n",
    "x_batch, y_batch = load_batch(path[0])\n",
    "\n",
    "y_batch = np.reshape(y_batch, (len(y_batch), 1))\n",
    "\n",
    "print(\"Train data (x_data): \", x_batch.shape)\n",
    "print(\"Train labels (y_data): \", y_batch.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the dataset and test the shapes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data (x_train):  (50000, 32, 32, 3)\n",
      "Train labels (y_train):  (50000, 1)\n",
      "Test data (x_test):  (10000, 32, 32, 3)\n",
      "Test labels (y_test):  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "path = 'cifar-10-batches-py'\n",
    "(x_train, y_train), (x_test, y_test) = load_data(path)\n",
    "\n",
    "print(\"Train data (x_train): \", x_train.shape)\n",
    "print(\"Train labels (y_train): \", y_train.shape)\n",
    "print(\"Test data (x_test): \", x_test.shape)\n",
    "print(\"Test labels (y_test): \", y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run Cross Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# ks = [1, 3, 5]\n",
    "ks = [1, 3, 5, 7, 9, 10, 15, 20, 50, 75, 100]\n",
    "# num_samples = 100\n",
    "num_samples = x_test.shape[0]\n",
    "\n",
    "x_test_batch, y_test_batch = load_batch(path[0])\n",
    "y_test_batch = np.reshape(y_test_batch, (len(y_test_batch), 1))\n",
    "\n",
    "predictions = np.zeros(num_samples)\n",
    "results = dict()\n",
    "\n",
    "# for distances in ks\n",
    "for k in ks:\n",
    "    # cross validate with each training set\n",
    "    for p in path:\n",
    "        x_batch, y_batch = load_batch(path[0])\n",
    "        y_batch = np.reshape(y_batch, (len(y_batch), 1))\n",
    "    \n",
    "        # i for each test sample\n",
    "        for i in range(num_samples):\n",
    "            # distances for one test sample wrt every sample in train batch\n",
    "            distances = [euclidean_distance(x_test_batch[i], x_batch[x]) for x in range(num_samples)]\n",
    "            # sorted minimum distances\n",
    "            min_distance_ids = np.argsort(distances)\n",
    "    \n",
    "            # take k distances and count number of accurate label predictions\n",
    "            label_count = np.zeros(10)\n",
    "            for j in range(k):\n",
    "                # increment the index of the label\n",
    "                label_count[y_batch[min_distance_ids[j]]] += 1\n",
    "                # the most recurring label is prediction for this sample\n",
    "                predictions[i] = np.argmax(label_count)\n",
    "    \n",
    "        accuracy = np.mean(predictions == y_test[:num_samples])\n",
    "    \n",
    "    results[k] = accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}